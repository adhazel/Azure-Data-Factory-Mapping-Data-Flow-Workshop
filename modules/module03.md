# Module 03 - Two Ways to do a Basic Copy

[< Previous Module](../modules/module02.md) - **[Home](../README.md)** - [Next Module >](../modules/module04.md)

## :loudspeaker: Introduction

A basic data movement can be accomplished two ways in Azure Data Factory. This module will demonstrate both:

* Pipeline copy
* Mapping data flows copy

## :bookmark_tabs: Table of Contents

If there are multiple sections to this page, add a Table of Contents with jump links.

| #  | Section |
| --- | --- |
| 1 | [Stage data in the data lake](#1stage-data-in-the-data-lake) |
| 2 | [Pipeline copy](#2pipeline-copy) |
| 3 | [Mapping data flows copy](#3mapping-data-flows-copy) |

<div align="right"><a href="#module-03---two-ways-to-do-a-basic-copy">↥ back to top</a></div>

## 1. Stage data in the data lake

The pipelines in this module use a 5 MB file named *NYCTripSmall.parquet*. Download this file from [../data_to_be_staged/adls\inbound\nyx_taxi_sample\NYCTripSmall.parquet](../data_to_be_staged/adls\inbound\nyx_taxi_sample\NYCTripSmall.parquet) and upload it into the Azure Storage Account lab resource named `dfmdf< Random string for your lab environment resources >adls`.

1. 

<div align="right"><a href="#module-03---two-ways-to-do-a-basic-copy">↥ back to top</a></div>

## 2. Pipeline Copy
pipeline copy

<div align="right"><a href="#module-03---two-ways-to-do-a-basic-copy">↥ back to top</a></div>

## 3. Mapping Data Flows Copy

mapping data flow copy

## :tada: Summary

You have now completed this module. 

[Continue >](../modules/module04.md)

